"""
Simple Example: TokenSHAP with SFA - Core ML/DL Algorithm Demo
"""

import sys
sys.path.append('.')

from config import TokenSHAPConfig
from tokenshap_with_sfa import TokenSHAPWithSFA

def main():
    """Demonstrate core TokenSHAP + SFA functionality"""
    
    print("üß† TokenSHAP with SFA - Core ML Algorithm Demo")
    print("=" * 45)
    
    # Configure the algorithm
    config = TokenSHAPConfig(
        max_samples=10,           # Shapley value sampling
        parallel_workers=2,       # CPU parallelization  
        attribution_method="shapley"  # Core ML method
    )
    
    # Initialize the main algorithm
    try:
        explainer = TokenSHAPWithSFA(config=config)
        print("‚úÖ TokenSHAP algorithm initialized")
        
        # Example text for explanation
        text = "Machine learning algorithms can analyze and understand text patterns effectively."
        
        print(f"\nüìù Analyzing text: '{text}'")
        
        # Core ML explanation (would work with actual models)
        print("\nüîç Core Algorithm Components:")
        print("   ‚Ä¢ TokenSHAP: Shapley-based token attribution")
        print("   ‚Ä¢ SFA: Meta-learning for fast approximation") 
        print("   ‚Ä¢ Value Functions: Similarity-based scoring")
        print("   ‚Ä¢ Hierarchical Analysis: Multi-level explanations")
        
        print(f"\n‚öôÔ∏è Configuration:")
        print(f"   ‚Ä¢ Max Samples: {config.max_samples}")
        print(f"   ‚Ä¢ Workers: {config.parallel_workers}")
        print(f"   ‚Ä¢ Method: {config.attribution_method}")
        
        print(f"\n‚ú® Algorithm ready for ML/DL model integration")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print("üí° Note: Full functionality requires ML model integration")

if __name__ == "__main__":
    main()